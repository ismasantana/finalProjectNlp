{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-NLP-PF-Classificacao.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G0OP-a3uYGJI"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi8wWbP7Rxwc"
      },
      "source": [
        "# Projeto Final\r\n",
        "**Disciplina:** Aprendizado Profundo para Processamento de Linguagem Natural\r\n",
        "\r\n",
        "**Aluno:** Ismael Santana Silva\r\n",
        "\r\n",
        "**Notebook disponível em:** https://colab.research.google.com/drive/16Hzb_c_LJkmWT582nUhpEuI8Oh37y61U?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O804QVb3Ar6C"
      },
      "source": [
        "## Avaliação da Classificação Automática"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypR-eKe0Yi82"
      },
      "source": [
        "Neste Jupyter NoteBook é realizada a avaliação dos algoritmos Random Forest e LSTM para classificar as sentenças coletadas entre escritas por pessoas com Depressão ou Controle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHxLH0jTR_11"
      },
      "source": [
        "Conectando no Google Drive para recuperar os arquivos com os dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS_UcVgeQ3bg",
        "outputId": "4cd2e0ca-6aec-46d3-b602-1d181d9508a7"
      },
      "source": [
        "from google.colab import drive\r\n",
        " \r\n",
        "drive.mount('/gdrive')\r\n",
        "\r\n",
        "%cd /gdrive/'MyDrive'/NLP/ProjetoFinal"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/NLP/ProjetoFinal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQBs_l0XSGlr"
      },
      "source": [
        "Importando bibliotecas que foram utilizadas na elaboração deste projeto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdPPZvSaTAll"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "from sklearn.metrics import make_scorer, recall_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-C9Ybi5STkv"
      },
      "source": [
        "Carregando os dados que foram pré-processados no notebook `01-NLP-PF-PreProcessamentoDados.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFyIntlzLJjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "7dfccfff-f91e-44fc-dadc-ae20ea055d7b"
      },
      "source": [
        "dataset = pd.read_csv('pos_tag_frequencies.csv')\r\n",
        "dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SYM</th>\n",
              "      <th>ADD</th>\n",
              "      <th>UH</th>\n",
              "      <th>NNP</th>\n",
              "      <th>NN</th>\n",
              "      <th>''</th>\n",
              "      <th>NFP</th>\n",
              "      <th>``</th>\n",
              "      <th>XX</th>\n",
              "      <th>LS</th>\n",
              "      <th>PRP</th>\n",
              "      <th>WDT</th>\n",
              "      <th>PRP$</th>\n",
              "      <th>JJS</th>\n",
              "      <th>WRB</th>\n",
              "      <th>JJR</th>\n",
              "      <th>-LRB-</th>\n",
              "      <th>FW</th>\n",
              "      <th>PDT</th>\n",
              "      <th>VBN</th>\n",
              "      <th>RB</th>\n",
              "      <th>VBG</th>\n",
              "      <th>CC</th>\n",
              "      <th>CD</th>\n",
              "      <th>RBR</th>\n",
              "      <th>DT</th>\n",
              "      <th>NNPS</th>\n",
              "      <th>VBP</th>\n",
              "      <th>MD</th>\n",
              "      <th>WP</th>\n",
              "      <th>VBD</th>\n",
              "      <th>-RRB-</th>\n",
              "      <th>RBS</th>\n",
              "      <th>RP</th>\n",
              "      <th>WP$</th>\n",
              "      <th>_SP</th>\n",
              "      <th>AFX</th>\n",
              "      <th>POS</th>\n",
              "      <th>VB</th>\n",
              "      <th>EX</th>\n",
              "      <th>TO</th>\n",
              "      <th>JJ</th>\n",
              "      <th>NNS</th>\n",
              "      <th>VBZ</th>\n",
              "      <th>$</th>\n",
              "      <th>IN</th>\n",
              "      <th>depression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>63</td>\n",
              "      <td>14</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>55</td>\n",
              "      <td>54</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149089</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149090</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149091</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149092</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149093</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149094 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        SYM  ADD  UH  NNP   NN  ''  NFP  ...  TO  JJ  NNS  VBZ  $   IN  depression\n",
              "0         0    0   1    8  113   0    0  ...  29  55   54   26  0  104           1\n",
              "1         0    0   0    1    1   0    0  ...   0   0    0    0  0    2           1\n",
              "2         0    0   0    1   30   0    0  ...   4  17   13   10  0   26           1\n",
              "3         0    0   0    1    8   0    0  ...   0   2    2    3  0    8           1\n",
              "4         0    0   1    1    8   0    0  ...   4   3    5    4  0   11           1\n",
              "...     ...  ...  ..  ...  ...  ..  ...  ...  ..  ..  ...  ... ..  ...         ...\n",
              "149089    0    0   1    0    1   0    0  ...   0   2    1    1  0    2           0\n",
              "149090    0    0   1    0    4   0    0  ...   0   1    0    1  0    1           0\n",
              "149091    0    0   1    0    1   0    0  ...   3   3    1    1  0    1           0\n",
              "149092    0    0   0    0    0   0    0  ...   0   0    0    0  0    0           0\n",
              "149093    0    0   0    1    0   0    0  ...   0   0    0    0  0    0           0\n",
              "\n",
              "[149094 rows x 47 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU0WPgypYU16"
      },
      "source": [
        "## Avaliação do classificação Random Forest:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2fz3FK8eeSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bae9151-48e2-42f1-e626-7868e0981673"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "from sklearn.metrics import make_scorer, recall_score\r\n",
        "\r\n",
        "clf = RandomForestClassifier(random_state=11)\r\n",
        "X = dataset.drop(columns=['depression'])\r\n",
        "y = dataset['depression']\r\n",
        "scoring = {'f1_macro':'f1_macro', 'accuracy':'accuracy','roc_auc':'roc_auc','precision':'precision', 'recall':'recall',\r\n",
        "            'sensitivity': make_scorer(recall_score, pos_label=1), 'specificity': make_scorer(recall_score, pos_label=0)}\r\n",
        "\r\n",
        "s = cross_validate(clf, X, y, cv=10,scoring=scoring)\r\n",
        "\r\n",
        "print('test_roc_auc:', np.mean(s['test_roc_auc']), 'std:', np.std(s['test_roc_auc']))\r\n",
        "print('test_sensitivity:', np.mean(s['test_sensitivity']), 'std:', np.std(s['test_sensitivity']))\r\n",
        "print('test_specificity:', np.mean(s['test_specificity']), 'std:', np.std(s['test_specificity'])) \r\n",
        "print('test_f1_macro:',np.mean(s['test_f1_macro']), 'std:', np.std(s['test_f1_macro']))\r\n",
        "print('test_accuracy:', np.mean(s['test_accuracy']), 'std:', np.std(s['test_accuracy']))\r\n",
        "print('test_precision:', np.mean(s['test_precision']), 'std:', np.std(s['test_precision']))\r\n",
        "print('test_recall:', np.mean(s['test_recall']), 'std:', np.std(s['test_recall']))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_roc_auc: 0.7696179717487217 std: 0.07838092176720658\n",
            "test_sensitivity: 0.24605317582050518 std: 0.12665860519757585\n",
            "test_specificity: 0.9851604113643511 std: 0.007818619859276602\n",
            "test_f1_macro: 0.6451003938550413 std: 0.08456649625014678\n",
            "test_accuracy: 0.8774327720070957 std: 0.023164049221429978\n",
            "test_precision: 0.7030065931032025 std: 0.18539258804516762\n",
            "test_recall: 0.24605317582050518 std: 0.12665860519757585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6iwRc5GEOhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71dcb2fe-aa9b-489f-9108-a3c791255a84"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "y_pred = cross_val_predict(clf, X, y, cv=10)\r\n",
        "conf_mat = confusion_matrix(y, y_pred)\r\n",
        "conf_mat"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[125473,   1890],\n",
              "       [ 16384,   5347]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixTX0qIoH_Ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4710ca-35d2-4778-8034-cac27fd6c9ab"
      },
      "source": [
        "X2 = X.applymap(lambda x: 1 if x > 0 else 0)\r\n",
        "\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "from sklearn.metrics import make_scorer, recall_score\r\n",
        "\r\n",
        "clf = RandomForestClassifier(random_state=11)\r\n",
        "\r\n",
        "scoring = {'f1_macro':'f1_macro', 'accuracy':'accuracy','roc_auc':'roc_auc','precision':'precision', 'recall':'recall',\r\n",
        "            'sensitivity': make_scorer(recall_score, pos_label=1), 'specificity': make_scorer(recall_score, pos_label=0)}\r\n",
        "\r\n",
        "s = cross_validate(clf, X2, y, cv=10,scoring=scoring)\r\n",
        "\r\n",
        "print('test_roc_auc:', np.mean(s['test_roc_auc']), 'std:', np.std(s['test_roc_auc']))\r\n",
        "print('test_sensitivity:', np.mean(s['test_sensitivity']), 'std:', np.std(s['test_sensitivity']))\r\n",
        "print('test_specificity:', np.mean(s['test_specificity']), 'std:', np.std(s['test_specificity'])) \r\n",
        "print('test_f1_macro:',np.mean(s['test_f1_macro']), 'std:', np.std(s['test_f1_macro']))\r\n",
        "print('test_accuracy:', np.mean(s['test_accuracy']), 'std:', np.std(s['test_accuracy']))\r\n",
        "print('test_precision:', np.mean(s['test_precision']), 'std:', np.std(s['test_precision']))\r\n",
        "print('test_recall:', np.mean(s['test_recall']), 'std:', np.std(s['test_recall']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_roc_auc: 0.692114761183519 std: 0.06208882788029325\n",
            "test_sensitivity: 0.18650871636556537 std: 0.09284906985900455\n",
            "test_specificity: 0.9624851743111412 std: 0.0035676698172190874\n",
            "test_f1_macro: 0.5873519226190496 std: 0.05906162896339142\n",
            "test_accuracy: 0.8493835434184916 std: 0.014814888497824596\n",
            "test_precision: 0.43556416479242654 std: 0.1221790365363392\n",
            "test_recall: 0.18650871636556537 std: 0.09284906985900455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWHwOS1TZrM8"
      },
      "source": [
        "## Avaliação da LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9FB3HYo6-zO"
      },
      "source": [
        "Instalando o tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH_FAfIz5dEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ab9b6b-79cb-43aa-d82b-909658d1863a"
      },
      "source": [
        "#!pip install -q tensorflow_datasets\r\n",
        "!pip install -q -U tensorflow\r\n",
        "!pip install -q -U tensorflow-text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4MB 5.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z682XYsrjkY9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import collections\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5eWCo88voPY"
      },
      "source": [
        "Carregando os dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC25Lu1Yvuqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "70d59f01-9076-4061-e52f-c4b6f8a3eb36"
      },
      "source": [
        "import pandas as pd\n",
        "#dfFrequency = pd.read_csv('pos_tag_frequencies.csv')\n",
        "dfFrequency = dataset\n",
        "dfPosTag = pd.read_csv('corpus-pos-tag',names=['text', 'label'])\n",
        "\n",
        "dfPosTag"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PRP VBP IN JJS NNS WP VBP RB IN DT NN IN DT NN...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NNP CC PRP VBP IN PRP VBP IN DT NN CC VB PRP</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PRP VBP RB WRB PRP VBZ VBG DT JJ NN PRP VBP RB...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JJS NN IN JJ NNS MD VB IN PRP MD VB DT NN WRB ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PRP VBP TO VB IN DT PRP VBP IN NNS VBP UH CC R...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149089</th>\n",
              "      <td>UH DT VBZ RB JJ PRP VBP NN VBP RB JJ IN PDT DT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149090</th>\n",
              "      <td>UH PRP VBP RB DT JJ NN CC PRP VBP IN DT NN CC ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149091</th>\n",
              "      <td>JJ PRP VBP PRP VBP VBP DT JJ PRP VBP RB VBD TO...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149092</th>\n",
              "      <td>_SP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149093</th>\n",
              "      <td>NNP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149094 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  label\n",
              "0       PRP VBP IN JJS NNS WP VBP RB IN DT NN IN DT NN...      1\n",
              "1            NNP CC PRP VBP IN PRP VBP IN DT NN CC VB PRP      1\n",
              "2       PRP VBP RB WRB PRP VBZ VBG DT JJ NN PRP VBP RB...      1\n",
              "3       JJS NN IN JJ NNS MD VB IN PRP MD VB DT NN WRB ...      1\n",
              "4       PRP VBP TO VB IN DT PRP VBP IN NNS VBP UH CC R...      1\n",
              "...                                                   ...    ...\n",
              "149089  UH DT VBZ RB JJ PRP VBP NN VBP RB JJ IN PDT DT...      0\n",
              "149090  UH PRP VBP RB DT JJ NN CC PRP VBP IN DT NN CC ...      0\n",
              "149091  JJ PRP VBP PRP VBP VBP DT JJ PRP VBP RB VBD TO...      0\n",
              "149092                                                _SP      0\n",
              "149093                                                NNP      0\n",
              "\n",
              "[149094 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH3x-FKKAmk9"
      },
      "source": [
        "Criação de uma função para calculo da `marcro-f1` para avaliação do algoritmo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7tS2gu027uh"
      },
      "source": [
        "from sklearn.metrics import f1_score\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "tf.config.run_functions_eagerly(True)\r\n",
        "def macro_f1(y_true, y_pred): \r\n",
        "  return f1_score(  K.eval(y_true), K.eval(K.round(K.clip(y_pred, 0, 1))), average='macro')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjQaYFt8A7aF"
      },
      "source": [
        "Avalição de uma LSTM para classificação dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCTFiwKF8LGQ",
        "outputId": "7e3fa01a-5429-453f-8325-0229f8428cc0"
      },
      "source": [
        "from sklearn.model_selection import KFold\r\n",
        "\r\n",
        "n_folds = 10\r\n",
        "fold = 1\r\n",
        "kf = KFold(n_splits=n_folds, shuffle=True)\r\n",
        "score_acc = 0.0\r\n",
        "score_f1 = 0.0\r\n",
        "score_macro_f1 = 0.0\r\n",
        "for train_index, test_index in kf.split(dfPosTag):#validação cruzada\r\n",
        "  X_train, X_test = dfPosTag['text'].astype(str).iloc[train_index], dfPosTag['text'].astype(str).iloc[test_index]\r\n",
        "  y_train, y_test = dfPosTag['label'].iloc[train_index], dfPosTag['label'].iloc[test_index]\r\n",
        "\r\n",
        "  train_dataset = (\r\n",
        "      tf.data.Dataset.from_tensor_slices(\r\n",
        "          (\r\n",
        "              tf.cast(X_train, tf.string),\r\n",
        "              tf.cast(y_train, tf.int32)\r\n",
        "          )\r\n",
        "      )\r\n",
        "  )\r\n",
        "  test_dataset = (\r\n",
        "      tf.data.Dataset.from_tensor_slices(\r\n",
        "          (\r\n",
        "              tf.cast(X_test, tf.string),\r\n",
        "              tf.cast(y_test, tf.int32)\r\n",
        "          )\r\n",
        "      )\r\n",
        "  )\r\n",
        "\r\n",
        "  BUFFER_SIZE = 10000\r\n",
        "  BATCH_SIZE = 64\r\n",
        "  train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\r\n",
        "  test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\r\n",
        "\r\n",
        "  VOCAB_SIZE=dfFrequency.shape[1]-1\r\n",
        "  encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\r\n",
        "      max_tokens=VOCAB_SIZE)\r\n",
        "  encoder.adapt(train_dataset.map(lambda text, label: text))\r\n",
        "\r\n",
        "  model = tf.keras.Sequential([\r\n",
        "      encoder,\r\n",
        "      tf.keras.layers.Embedding(\r\n",
        "          input_dim=len(encoder.get_vocabulary()),\r\n",
        "          output_dim=64,\r\n",
        "          # Use masking to handle the variable sequence lengths\r\n",
        "          mask_zero=True),\r\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "      tf.keras.layers.Dense(1)\r\n",
        "  ])\r\n",
        "\r\n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "                optimizer=tf.keras.optimizers.Adam(1e-4),\r\n",
        "                metrics=['accuracy',  macro_f1]\r\n",
        "              )\r\n",
        "\r\n",
        "  history = model.fit(train_dataset, epochs=10,\r\n",
        "                      #validation_data=test_dataset,                       \r\n",
        "                      validation_steps=30)\r\n",
        "\r\n",
        "  test_loss, test_acc, test_macro_f1 = model.evaluate(test_dataset)\r\n",
        "  score_acc += test_acc\r\n",
        "  score_macro_f1 += test_macro_f1\r\n",
        "  print('Fold: {}'.format(fold))\r\n",
        "  fold+=1\r\n",
        "  print('Teste loss: {}'.format(test_loss)) \r\n",
        "  print('Teste acurácia: {}'.format(test_acc))\r\n",
        "  print('Teste macro-f1: {}'.format(test_macro_f1))\r\n",
        "\r\n",
        "print('Final: macro-f1:', score_macro_f1/n_folds, 'acurácia:',  score_acc/n_folds)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 160s 67ms/step - loss: 0.3404 - accuracy: 0.7534 - macro_f1: 0.5279\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.5651 - accuracy: 0.8263 - macro_f1: 0.5642\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.6346 - accuracy: 0.7389 - macro_f1: 0.5181\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.6419 - accuracy: 0.7290 - macro_f1: 0.5141\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6465 - accuracy: 0.7210 - macro_f1: 0.5112\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6549 - accuracy: 0.7816 - macro_f1: 0.5449\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5571 - accuracy: 0.8031 - macro_f1: 0.5582\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5218 - accuracy: 0.8130 - macro_f1: 0.5632\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.5346 - accuracy: 0.8091 - macro_f1: 0.5593\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5490 - accuracy: 0.8014 - macro_f1: 0.5538\n",
            "233/233 [==============================] - 9s 41ms/step - loss: 0.9329 - accuracy: 0.8518 - macro_f1: 0.8512\n",
            "Fold: 1\n",
            "Teste loss: 0.9329326152801514\n",
            "Teste acurácia: 0.8517773151397705\n",
            "Teste macro-f1: 0.851155161857605\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 140s 66ms/step - loss: 0.3460 - accuracy: 0.7453 - macro_f1: 0.5213\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 135s 65ms/step - loss: 0.6660 - accuracy: 0.8154 - macro_f1: 0.5607\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6920 - accuracy: 0.7536 - macro_f1: 0.5256\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6169 - accuracy: 0.7858 - macro_f1: 0.5418\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6550 - accuracy: 0.7548 - macro_f1: 0.5267\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6313 - accuracy: 0.7662 - macro_f1: 0.5231\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6840 - accuracy: 0.7479 - macro_f1: 0.5260\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6236 - accuracy: 0.7971 - macro_f1: 0.5562\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5444 - accuracy: 0.8069 - macro_f1: 0.5603\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5616 - accuracy: 0.7942 - macro_f1: 0.5500\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 1.1323 - accuracy: 0.8524 - macro_f1: 0.8514\n",
            "Fold: 2\n",
            "Teste loss: 1.1323449611663818\n",
            "Teste acurácia: 0.8523809313774109\n",
            "Teste macro-f1: 0.851410448551178\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 142s 67ms/step - loss: 0.3385 - accuracy: 0.7574 - macro_f1: 0.5223\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.7230 - accuracy: 0.7868 - macro_f1: 0.5420\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6717 - accuracy: 0.7670 - macro_f1: 0.5300\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6735 - accuracy: 0.7573 - macro_f1: 0.5242\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.7262 - accuracy: 0.7360 - macro_f1: 0.5083\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6213 - accuracy: 0.8026 - macro_f1: 0.5497\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 140s 67ms/step - loss: 0.5417 - accuracy: 0.8131 - macro_f1: 0.5582\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 140s 67ms/step - loss: 0.5527 - accuracy: 0.8108 - macro_f1: 0.5543\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 141s 67ms/step - loss: 0.5326 - accuracy: 0.8127 - macro_f1: 0.5574\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 141s 67ms/step - loss: 0.5456 - accuracy: 0.8073 - macro_f1: 0.5614\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 0.9791 - accuracy: 0.8620 - macro_f1: 0.8604\n",
            "Fold: 3\n",
            "Teste loss: 0.9790525436401367\n",
            "Teste acurácia: 0.8620389103889465\n",
            "Teste macro-f1: 0.8603527545928955\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 143s 67ms/step - loss: 0.3429 - accuracy: 0.7484 - macro_f1: 0.5255\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 141s 67ms/step - loss: 0.6726 - accuracy: 0.8160 - macro_f1: 0.5569\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.7048 - accuracy: 0.7271 - macro_f1: 0.5139\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.6970 - accuracy: 0.7183 - macro_f1: 0.5078\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 140s 67ms/step - loss: 0.6428 - accuracy: 0.7433 - macro_f1: 0.5223\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 140s 67ms/step - loss: 0.6498 - accuracy: 0.7784 - macro_f1: 0.5440\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 141s 67ms/step - loss: 0.6172 - accuracy: 0.7796 - macro_f1: 0.5398\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 140s 67ms/step - loss: 0.6365 - accuracy: 0.7677 - macro_f1: 0.5394\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 140s 67ms/step - loss: 0.6331 - accuracy: 0.7817 - macro_f1: 0.5444\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 143s 68ms/step - loss: 0.6355 - accuracy: 0.7944 - macro_f1: 0.5482\n",
            "233/233 [==============================] - 10s 44ms/step - loss: 1.0067 - accuracy: 0.8520 - macro_f1: 0.8513\n",
            "Fold: 4\n",
            "Teste loss: 1.0067490339279175\n",
            "Teste acurácia: 0.8520455956459045\n",
            "Teste macro-f1: 0.8512744307518005\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 142s 67ms/step - loss: 0.3495 - accuracy: 0.7443 - macro_f1: 0.5218\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.7159 - accuracy: 0.7850 - macro_f1: 0.5423\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.6547 - accuracy: 0.7299 - macro_f1: 0.5175\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.6194 - accuracy: 0.7812 - macro_f1: 0.5361\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 140s 67ms/step - loss: 0.6355 - accuracy: 0.7513 - macro_f1: 0.5247\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6106 - accuracy: 0.7671 - macro_f1: 0.5352\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6237 - accuracy: 0.7881 - macro_f1: 0.5443\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5828 - accuracy: 0.7960 - macro_f1: 0.5513\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5590 - accuracy: 0.8126 - macro_f1: 0.5671\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5355 - accuracy: 0.8135 - macro_f1: 0.5633\n",
            "233/233 [==============================] - 10s 42ms/step - loss: 1.1208 - accuracy: 0.8497 - macro_f1: 0.8476\n",
            "Fold: 5\n",
            "Teste loss: 1.1207865476608276\n",
            "Teste acurácia: 0.8496881127357483\n",
            "Teste macro-f1: 0.8476225733757019\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.3511 - accuracy: 0.7378 - macro_f1: 0.5177\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6746 - accuracy: 0.8099 - macro_f1: 0.5515\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6928 - accuracy: 0.7428 - macro_f1: 0.5227\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6670 - accuracy: 0.7479 - macro_f1: 0.5242\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6495 - accuracy: 0.7651 - macro_f1: 0.5286\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6646 - accuracy: 0.7734 - macro_f1: 0.5357\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 137s 66ms/step - loss: 0.6096 - accuracy: 0.7871 - macro_f1: 0.5470\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6100 - accuracy: 0.7999 - macro_f1: 0.5477\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6163 - accuracy: 0.8018 - macro_f1: 0.5571\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5681 - accuracy: 0.8111 - macro_f1: 0.5626\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 1.1626 - accuracy: 0.8555 - macro_f1: 0.8552\n",
            "Fold: 6\n",
            "Teste loss: 1.1626240015029907\n",
            "Teste acurácia: 0.8555235266685486\n",
            "Teste macro-f1: 0.8551751375198364\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.3367 - accuracy: 0.7564 - macro_f1: 0.5284\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.7516 - accuracy: 0.7850 - macro_f1: 0.5445\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.7251 - accuracy: 0.7361 - macro_f1: 0.5221\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6468 - accuracy: 0.7633 - macro_f1: 0.5349\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6239 - accuracy: 0.7882 - macro_f1: 0.5413\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6315 - accuracy: 0.7799 - macro_f1: 0.5369\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5154 - accuracy: 0.8351 - macro_f1: 0.5774\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5450 - accuracy: 0.8173 - macro_f1: 0.5612\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5771 - accuracy: 0.7992 - macro_f1: 0.5547\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.5832 - accuracy: 0.8041 - macro_f1: 0.5574\n",
            "233/233 [==============================] - 10s 41ms/step - loss: 1.1688 - accuracy: 0.8559 - macro_f1: 0.8554\n",
            "Fold: 7\n",
            "Teste loss: 1.1688445806503296\n",
            "Teste acurácia: 0.8558588624000549\n",
            "Teste macro-f1: 0.8553506731987\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 140s 66ms/step - loss: 0.3444 - accuracy: 0.7499 - macro_f1: 0.5240\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.7766 - accuracy: 0.7783 - macro_f1: 0.5399\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.7520 - accuracy: 0.7061 - macro_f1: 0.5042\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6307 - accuracy: 0.7712 - macro_f1: 0.5391\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6243 - accuracy: 0.7869 - macro_f1: 0.5447\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6447 - accuracy: 0.7794 - macro_f1: 0.5389\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5629 - accuracy: 0.8090 - macro_f1: 0.5629\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5601 - accuracy: 0.8123 - macro_f1: 0.5713\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5394 - accuracy: 0.8028 - macro_f1: 0.5620\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5667 - accuracy: 0.7953 - macro_f1: 0.5562\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.9989 - accuracy: 0.8520 - macro_f1: 0.8512\n",
            "Fold: 8\n",
            "Teste loss: 0.9989392161369324\n",
            "Teste acurácia: 0.8519685864448547\n",
            "Teste macro-f1: 0.8512455224990845\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 139s 66ms/step - loss: 0.3403 - accuracy: 0.7557 - macro_f1: 0.5271\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.7138 - accuracy: 0.7941 - macro_f1: 0.5468\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6904 - accuracy: 0.7621 - macro_f1: 0.5365\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6514 - accuracy: 0.7745 - macro_f1: 0.5307\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6346 - accuracy: 0.7735 - macro_f1: 0.5305\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.5966 - accuracy: 0.7891 - macro_f1: 0.5399\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6793 - accuracy: 0.7705 - macro_f1: 0.5293\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.6120 - accuracy: 0.7969 - macro_f1: 0.5474\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5686 - accuracy: 0.8202 - macro_f1: 0.5660\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 138s 66ms/step - loss: 0.5635 - accuracy: 0.7992 - macro_f1: 0.5564\n",
            "233/233 [==============================] - 10s 43ms/step - loss: 0.9277 - accuracy: 0.8545 - macro_f1: 0.8545\n",
            "Fold: 9\n",
            "Teste loss: 0.9277086853981018\n",
            "Teste acurácia: 0.85451740026474\n",
            "Teste macro-f1: 0.8545003533363342\n",
            "Epoch 1/10\n",
            "2097/2097 [==============================] - 140s 66ms/step - loss: 0.3411 - accuracy: 0.7563 - macro_f1: 0.5273\n",
            "Epoch 2/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.7222 - accuracy: 0.8016 - macro_f1: 0.5520\n",
            "Epoch 3/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6386 - accuracy: 0.7687 - macro_f1: 0.5349\n",
            "Epoch 4/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5970 - accuracy: 0.7777 - macro_f1: 0.5407\n",
            "Epoch 5/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6611 - accuracy: 0.7533 - macro_f1: 0.5319\n",
            "Epoch 6/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6748 - accuracy: 0.7822 - macro_f1: 0.5486\n",
            "Epoch 7/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.6141 - accuracy: 0.7735 - macro_f1: 0.5539\n",
            "Epoch 8/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.6033 - accuracy: 0.7856 - macro_f1: 0.5505\n",
            "Epoch 9/10\n",
            "2097/2097 [==============================] - 137s 65ms/step - loss: 0.5811 - accuracy: 0.7903 - macro_f1: 0.5527\n",
            "Epoch 10/10\n",
            "2097/2097 [==============================] - 136s 65ms/step - loss: 0.5384 - accuracy: 0.8230 - macro_f1: 0.5702\n",
            "233/233 [==============================] - 10s 41ms/step - loss: 0.9630 - accuracy: 0.8567 - macro_f1: 0.8557\n",
            "Fold: 10\n",
            "Teste loss: 0.9630183577537537\n",
            "Teste acurácia: 0.8566637635231018\n",
            "Teste macro-f1: 0.85570228099823\n",
            "Final: macro-f1: 0.8533789336681366 acurácia: 0.854246300458908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoJDDSikbm1y"
      },
      "source": [
        "## Conclusão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KqiD40FbmDl"
      },
      "source": [
        "- A LSTM apresentou melhores resultados do que o Random Forest considerando as métricas Macro-F1 e Acurácia (taxa de acerto);\r\n",
        "  - Provalmente esse melhor resultado foi porque a LSTM considera o contexto que a *tag* ocorre e o Random Forest não considera o contexto;\r\n",
        "    - Mesmo que de certa forma tenha sido perdida alguma informação ao optar por realizar a classificação pela *tag* e não pela palavra.\r\n",
        "- Trabalhos futuros:\r\n",
        "  - Aplicar abordagens de explicabilidade para enteder o modelo de classificação gerado pela LSTM e verificar a existência de padrões gramaticais que posso identicar pessoas com depressão.\r\n"
      ]
    }
  ]
}